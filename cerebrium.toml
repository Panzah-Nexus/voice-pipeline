[cerebrium.deployment]
name = "voice-pipeline-airgapped"
python_version = "3.11"
include = ["./*", "src/main.py", "cerebrium.toml"]
exclude = [".*", "venv", "__pycache__", "*.pyc", "node_modules"]
# docker_base_image_url = "nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04"  # Commented out - using custom Dockerfile

[cerebrium.runtime.custom]
port = 8000
entrypoint = "uvicorn src.pipecat_pipeline:app --host 0.0.0.0 --port 8000"
healthcheck_endpoint = "/health"
readycheck_endpoint = "/ready"
dockerfile_path = "./docker/Dockerfile"

[cerebrium.hardware]
cpu = 8
memory = 24.0
compute = "AMPERE_A10"
gpu_count = 1
provider = "aws"
region = "eu-west-2"

[cerebrium.scaling]
min_replicas = 0        # Keep one replica warm to avoid cold starts
max_replicas = 1
cooldown = 30
scaling_buffer = 0      # Keep a spare idle pod
response_grace_period = 900   # Keep long voice sessions alive (15 min)

[cerebrium.secrets]
HF_TOKEN = "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"
# NO OPENAI_API_KEY - Air-gapped deployment
PIPER_MODEL = "en_US-lessac-medium"
PIPER_SAMPLE_RATE = "22050"

# Dependencies are installed in Dockerfile for better control
# Minimal requirements - many packages are auto-installed as dependencies
# [cerebrium.dependencies.pip]
# fastapi = "0.115.5"
# uvicorn = "0.24.0"
# python-dotenv = "1.0.0"
# "pipecat-ai[silero,ultravox]" = "0.0.71"
# torch = "2.1.2"
# torchaudio = "2.1.2"
# librosa = "0.10.1" 